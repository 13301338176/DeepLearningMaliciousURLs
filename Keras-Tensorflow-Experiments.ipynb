{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras-Tensorflow Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "#from tensorflow.keras.utils.np_utils import to_categorical, normalize\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download datasets\n",
    "- if zip dataset files already exists; no download is done\n",
    "- force unzip all the .zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "URL=https://iscxdownloads.cs.unb.ca/iscxdownloads/ISCX-URL-2016/\n",
    "FILES=(ISCXURL2016.zip) \n",
    "for FILE in ${FILES[*]}; do\n",
    "    if [ ! -f \"$FILE\" ]; then\n",
    "        printf \"downloading %s\\n\" $FILE\n",
    "        curl -O $URL$FILE\n",
    "        # unzip files\n",
    "        echo 'unzipping ' $FILE\n",
    "        unzip -o $FILE #overwrite exiting files/folders if exists\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check CSV files inside FinalDataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_BestFirst.csv\t      Malware_Infogain_test.csv\r\n",
      "All_BestFirst_test.csv\t      Phishing_BestFirst.csv\r\n",
      "All.csv\t\t\t      Phishing.csv\r\n",
      "All_Infogain.csv\t      Phishing_Infogain.csv\r\n",
      "All_Infogain_test.csv\t      Phishing_Infogain_test.csv\r\n",
      "Defacement_BestFirst.csv      Spam_BestFirst.csv\r\n",
      "Defacement.csv\t\t      Spam_BestFirst_test.csv\r\n",
      "Defacement_Infogain.csv       Spam.csv\r\n",
      "Defacement_Infogain_test.csv  Spam_Infogain.csv\r\n",
      "Malware_BestFirst.csv\t      Spam_Infogain_test.csv\r\n",
      "Malware.csv\t\t      URL\r\n",
      "Malware_Infogain.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls FinalDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze FinalDataset/All.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FinalDataset/All.csv', low_memory=False)\n",
    "resultPath = 'results_keras_tensorflow'\n",
    "if not os.path.exists(resultPath):\n",
    "    print('result path {} created.'.format(resultPath))\n",
    "    os.mkdir(resultPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36707, 80)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.076923\n",
       "1        0.058824\n",
       "2        0.060606\n",
       "3        0.025974\n",
       "4        0.040816\n",
       "5        0.033898\n",
       "6        0.046512\n",
       "7        0.040000\n",
       "8        0.045455\n",
       "9        0.090909\n",
       "10       0.043478\n",
       "11       0.039216\n",
       "12       0.095238\n",
       "13       0.105263\n",
       "14       0.080000\n",
       "15       0.086957\n",
       "16       0.038462\n",
       "17       0.083333\n",
       "18       0.017241\n",
       "19       0.016949\n",
       "20       0.020408\n",
       "21       0.012579\n",
       "22       0.014815\n",
       "23       0.014085\n",
       "24       0.012500\n",
       "25       0.018182\n",
       "26       0.050000\n",
       "27       0.037037\n",
       "28       0.039216\n",
       "29       0.036364\n",
       "           ...   \n",
       "36677    0.792593\n",
       "36678    0.763636\n",
       "36679    0.794118\n",
       "36680    0.015625\n",
       "36681    0.057143\n",
       "36682    0.085106\n",
       "36683    0.662651\n",
       "36684    0.100000\n",
       "36685    0.407407\n",
       "36686    0.036364\n",
       "36687    0.578125\n",
       "36688    0.129412\n",
       "36689    0.712644\n",
       "36690    0.785047\n",
       "36691    0.086957\n",
       "36692    0.040000\n",
       "36693    0.068966\n",
       "36694    0.742574\n",
       "36695    0.015267\n",
       "36696    0.071429\n",
       "36697    0.985386\n",
       "36698    0.817308\n",
       "36699    0.275000\n",
       "36700    0.052632\n",
       "36701    0.105263\n",
       "36702    0.752212\n",
       "36703    0.016393\n",
       "36704    0.838710\n",
       "36705    0.755319\n",
       "36706    0.828283\n",
       "Name: argPathRatio, Length: 36707, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['argPathRatio'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Querylength', 'domain_token_count', 'path_token_count',\n",
       "       'avgdomaintokenlen', 'longdomaintokenlen', 'avgpathtokenlen', 'tld',\n",
       "       'charcompvowels', 'charcompace', 'ldl_url', 'ldl_domain', 'ldl_path',\n",
       "       'ldl_filename', 'ldl_getArg', 'dld_url', 'dld_domain', 'dld_path',\n",
       "       'dld_filename', 'dld_getArg', 'urlLen', 'domainlength', 'pathLength',\n",
       "       'subDirLen', 'fileNameLen', 'this.fileExtLen', 'ArgLen', 'pathurlRatio',\n",
       "       'ArgUrlRatio', 'argDomanRatio', 'domainUrlRatio', 'pathDomainRatio',\n",
       "       'argPathRatio', 'executable', 'isPortEighty', 'NumberofDotsinURL',\n",
       "       'ISIpAddressInDomainName', 'CharacterContinuityRate',\n",
       "       'LongestVariableValue', 'URL_DigitCount', 'host_DigitCount',\n",
       "       'Directory_DigitCount', 'File_name_DigitCount', 'Extension_DigitCount',\n",
       "       'Query_DigitCount', 'URL_Letter_Count', 'host_letter_count',\n",
       "       'Directory_LetterCount', 'Filename_LetterCount',\n",
       "       'Extension_LetterCount', 'Query_LetterCount', 'LongestPathTokenLength',\n",
       "       'Domain_LongestWordLength', 'Path_LongestWordLength',\n",
       "       'sub-Directory_LongestWordLength', 'Arguments_LongestWordLength',\n",
       "       'URL_sensitiveWord', 'URLQueries_variable', 'spcharUrl',\n",
       "       'delimeter_Domain', 'delimeter_path', 'delimeter_Count',\n",
       "       'NumberRate_URL', 'NumberRate_Domain', 'NumberRate_DirectoryName',\n",
       "       'NumberRate_FileName', 'NumberRate_Extension', 'NumberRate_AfterPath',\n",
       "       'SymbolCount_URL', 'SymbolCount_Domain', 'SymbolCount_Directoryname',\n",
       "       'SymbolCount_FileName', 'SymbolCount_Extension',\n",
       "       'SymbolCount_Afterpath', 'Entropy_URL', 'Entropy_Domain',\n",
       "       'Entropy_DirectoryName', 'Entropy_Filename', 'Entropy_Extension',\n",
       "       'Entropy_Afterpath', 'URL_Type_obf_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36707, 80)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>SymbolCount_FileName</th>\n",
       "      <th>SymbolCount_Extension</th>\n",
       "      <th>SymbolCount_Afterpath</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_DirectoryName</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>URL_Type_obf_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.726298</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.894886</td>\n",
       "      <td>0.850608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.688635</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.859793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.695049</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.640130</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.663210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>7.333334</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.681307</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "0            0                   4                 5                5.5   \n",
       "1            0                   4                 5                5.5   \n",
       "2            0                   4                 5                5.5   \n",
       "3            0                   4                12                5.5   \n",
       "4            0                   4                 6                5.5   \n",
       "\n",
       "   longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "0                  14         4.400000    4               8            3   \n",
       "1                  14         6.000000    4              12            4   \n",
       "2                  14         5.800000    4              12            5   \n",
       "3                  14         5.500000    4              32           16   \n",
       "4                  14         7.333334    4              18           11   \n",
       "\n",
       "   ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
       "0        0  ...                     1                      0   \n",
       "1        0  ...                     0                      0   \n",
       "2        0  ...                     0                      0   \n",
       "3        0  ...                     0                      0   \n",
       "4        0  ...                     0                      0   \n",
       "\n",
       "   SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  Entropy_DirectoryName  \\\n",
       "0                     -1     0.726298        0.784493               0.894886   \n",
       "1                     -1     0.688635        0.784493               0.814725   \n",
       "2                     -1     0.695049        0.784493               0.814725   \n",
       "3                     -1     0.640130        0.784493               0.814725   \n",
       "4                     -1     0.681307        0.784493               0.814725   \n",
       "\n",
       "   Entropy_Filename  Entropy_Extension  Entropy_Afterpath  URL_Type_obf_Type  \n",
       "0          0.850608                NaN               -1.0         Defacement  \n",
       "1          0.859793                0.0               -1.0         Defacement  \n",
       "2          0.801880                0.0               -1.0         Defacement  \n",
       "3          0.663210                0.0               -1.0         Defacement  \n",
       "4          0.804526                0.0               -1.0         Defacement  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>SymbolCount_FileName</th>\n",
       "      <th>SymbolCount_Extension</th>\n",
       "      <th>SymbolCount_Afterpath</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_DirectoryName</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>URL_Type_obf_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36702</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.690555</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.777498</td>\n",
       "      <td>0.690227</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>0.796205</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36703</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>8.461538</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.665492</td>\n",
       "      <td>0.820010</td>\n",
       "      <td>0.879588</td>\n",
       "      <td>0.674400</td>\n",
       "      <td>0.674671</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36704</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>16</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.656807</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.684777</td>\n",
       "      <td>0.713622</td>\n",
       "      <td>0.717187</td>\n",
       "      <td>0.705245</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36705</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>9</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.725963</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.871049</td>\n",
       "      <td>0.745932</td>\n",
       "      <td>0.758824</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36706</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>16</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.674351</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.697282</td>\n",
       "      <td>0.730563</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.769238</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "36702           29                   4                14           5.750000   \n",
       "36703            0                   4                13           3.750000   \n",
       "36704           58                   3                27           6.666666   \n",
       "36705           35                   3                13           4.333334   \n",
       "36706           40                   3                25           6.666666   \n",
       "\n",
       "       longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "36702                  12         3.666667    4              20           24   \n",
       "36703                   8         8.461538    4              24           23   \n",
       "36704                  16         3.375000    3              41           34   \n",
       "36705                   9         3.600000    3              15           13   \n",
       "36706                  16         3.250000    3              35           31   \n",
       "\n",
       "       ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
       "36702        3  ...                     3                      2   \n",
       "36703        0  ...                    16                     15   \n",
       "36704       20  ...                     8                      7   \n",
       "36705        7  ...                     9                      8   \n",
       "36706       19  ...                     7                      6   \n",
       "\n",
       "       SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  \\\n",
       "36702                      7     0.690555        0.791265   \n",
       "36703                     -1     0.665492        0.820010   \n",
       "36704                      9     0.656807        0.801139   \n",
       "36705                      3     0.725963        0.897617   \n",
       "36706                      7     0.674351        0.801139   \n",
       "\n",
       "       Entropy_DirectoryName  Entropy_Filename  Entropy_Extension  \\\n",
       "36702               0.777498          0.690227           0.656684   \n",
       "36703               0.879588          0.674400           0.674671   \n",
       "36704               0.684777          0.713622           0.717187   \n",
       "36705               0.871049          0.745932           0.758824   \n",
       "36706               0.697282          0.730563           0.731481   \n",
       "\n",
       "       Entropy_Afterpath  URL_Type_obf_Type  \n",
       "36702           0.796205               spam  \n",
       "36703          -1.000000               spam  \n",
       "36704           0.705245               spam  \n",
       "36705           0.790772               spam  \n",
       "36706           0.769238               spam  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "- dropped samples with Infinity values\n",
    "- dropped samples with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(csvFile):\n",
    "    pickleDump = '{}.pickle'.format(csvFile)\n",
    "    if os.path.exists(pickleDump):\n",
    "        df = pd.read_pickle(pickleDump)\n",
    "    else:\n",
    "        df = pd.read_csv(csvFile, low_memory=False)\n",
    "        # clean data\n",
    "        # strip the whitspaces from column names\n",
    "        df = df.rename(str.strip, axis='columns')\n",
    "        #df.drop(columns=[], inplace=True)\n",
    "        # drop missing values/NaN etc.\n",
    "        #df.dropna(inplace=True)\n",
    "        # drop Infinity rows and NaN string from each column\n",
    "        for col in df.columns:\n",
    "            indexNames = df[df[col]=='Infinity'].index\n",
    "            if not indexNames.empty:\n",
    "                print('deleting {} rows with Infinity in column {}'.format(len(indexNames), col))\n",
    "                df.drop(indexNames, inplace=True)\n",
    "            indexNames = df[df[col]==\"NaN\"].index\n",
    "            if not indexNames.empty:\n",
    "                print('deleting {} rows with NaN in column {}'.format(len(indexNames), col))\n",
    "                df.drop(indexNames, inplace=True)\n",
    "        \n",
    "        df.to_pickle(pickleDump)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loadData function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting 10 rows with Infinity in column argPathRatio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "dataFile = 'FinalDataset/All.csv'\n",
    "df = loadData(dataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Querylength', 'domain_token_count', 'path_token_count',\n",
       "       'avgdomaintokenlen', 'longdomaintokenlen', 'avgpathtokenlen', 'tld',\n",
       "       'charcompvowels', 'charcompace', 'ldl_url', 'ldl_domain', 'ldl_path',\n",
       "       'ldl_filename', 'ldl_getArg', 'dld_url', 'dld_domain', 'dld_path',\n",
       "       'dld_filename', 'dld_getArg', 'urlLen', 'domainlength', 'pathLength',\n",
       "       'subDirLen', 'fileNameLen', 'this.fileExtLen', 'ArgLen', 'pathurlRatio',\n",
       "       'ArgUrlRatio', 'argDomanRatio', 'domainUrlRatio', 'pathDomainRatio',\n",
       "       'argPathRatio', 'executable', 'isPortEighty', 'NumberofDotsinURL',\n",
       "       'ISIpAddressInDomainName', 'CharacterContinuityRate',\n",
       "       'LongestVariableValue', 'URL_DigitCount', 'host_DigitCount',\n",
       "       'Directory_DigitCount', 'File_name_DigitCount', 'Extension_DigitCount',\n",
       "       'Query_DigitCount', 'URL_Letter_Count', 'host_letter_count',\n",
       "       'Directory_LetterCount', 'Filename_LetterCount',\n",
       "       'Extension_LetterCount', 'Query_LetterCount', 'LongestPathTokenLength',\n",
       "       'Domain_LongestWordLength', 'Path_LongestWordLength',\n",
       "       'sub-Directory_LongestWordLength', 'Arguments_LongestWordLength',\n",
       "       'URL_sensitiveWord', 'URLQueries_variable', 'spcharUrl',\n",
       "       'delimeter_Domain', 'delimeter_path', 'delimeter_Count',\n",
       "       'NumberRate_URL', 'NumberRate_Domain', 'NumberRate_DirectoryName',\n",
       "       'NumberRate_FileName', 'NumberRate_Extension', 'NumberRate_AfterPath',\n",
       "       'SymbolCount_URL', 'SymbolCount_Domain', 'SymbolCount_Directoryname',\n",
       "       'SymbolCount_FileName', 'SymbolCount_Extension',\n",
       "       'SymbolCount_Afterpath', 'Entropy_URL', 'Entropy_Domain',\n",
       "       'Entropy_DirectoryName', 'Entropy_Filename', 'Entropy_Extension',\n",
       "       'Entropy_Afterpath', 'URL_Type_obf_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36697, 80)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "5    NaN\n",
       "6    NaN\n",
       "7    NaN\n",
       "8    NaN\n",
       "9    1.0\n",
       "Name: NumberRate_Extension, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NumberRate_Extension'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36697, 80)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>SymbolCount_FileName</th>\n",
       "      <th>SymbolCount_Extension</th>\n",
       "      <th>SymbolCount_Afterpath</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_DirectoryName</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>URL_Type_obf_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.726298</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.894886</td>\n",
       "      <td>0.850608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.688635</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.859793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.695049</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.640130</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.663210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>7.333334</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.681307</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "0            0                   4                 5                5.5   \n",
       "1            0                   4                 5                5.5   \n",
       "2            0                   4                 5                5.5   \n",
       "3            0                   4                12                5.5   \n",
       "4            0                   4                 6                5.5   \n",
       "\n",
       "   longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "0                  14         4.400000    4               8            3   \n",
       "1                  14         6.000000    4              12            4   \n",
       "2                  14         5.800000    4              12            5   \n",
       "3                  14         5.500000    4              32           16   \n",
       "4                  14         7.333334    4              18           11   \n",
       "\n",
       "   ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
       "0        0  ...                     1                      0   \n",
       "1        0  ...                     0                      0   \n",
       "2        0  ...                     0                      0   \n",
       "3        0  ...                     0                      0   \n",
       "4        0  ...                     0                      0   \n",
       "\n",
       "   SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  Entropy_DirectoryName  \\\n",
       "0                     -1     0.726298        0.784493               0.894886   \n",
       "1                     -1     0.688635        0.784493               0.814725   \n",
       "2                     -1     0.695049        0.784493               0.814725   \n",
       "3                     -1     0.640130        0.784493               0.814725   \n",
       "4                     -1     0.681307        0.784493               0.814725   \n",
       "\n",
       "   Entropy_Filename  Entropy_Extension  Entropy_Afterpath  URL_Type_obf_Type  \n",
       "0          0.850608                NaN               -1.0         Defacement  \n",
       "1          0.859793                0.0               -1.0         Defacement  \n",
       "2          0.801880                0.0               -1.0         Defacement  \n",
       "3          0.663210                0.0               -1.0         Defacement  \n",
       "4          0.804526                0.0               -1.0         Defacement  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with FinalDataset/All.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total samples for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| phishing | 7577 |\n",
      "| malware | 6711 |\n",
      "| Defacement | 7930 |\n",
      "| spam | 6698 |\n",
      "| benign | 7781 |\n"
     ]
    }
   ],
   "source": [
    "# total samples\n",
    "label = 'URL_Type_obf_Type'\n",
    "lblTypes = set(df[label])\n",
    "for lbl in lblTypes:\n",
    "    print('| {} | {} |'.format(lbl, len(df[df[label] == lbl].index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'FinalDataset'\n",
    "dep_var = label\n",
    "cat_names = []\n",
    "cont_names = list(set(df.columns) - set(cat_names) - set([dep_var]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Extension_LetterCount',\n",
       " 'longdomaintokenlen',\n",
       " 'pathDomainRatio',\n",
       " 'Arguments_LongestWordLength',\n",
       " 'LongestVariableValue',\n",
       " 'this.fileExtLen',\n",
       " 'NumberRate_AfterPath',\n",
       " 'dld_url',\n",
       " 'Query_DigitCount',\n",
       " 'SymbolCount_URL',\n",
       " 'ldl_url',\n",
       " 'avgpathtokenlen',\n",
       " 'Directory_LetterCount',\n",
       " 'ArgUrlRatio',\n",
       " 'URL_sensitiveWord',\n",
       " 'SymbolCount_Directoryname',\n",
       " 'URL_Letter_Count',\n",
       " 'URL_DigitCount',\n",
       " 'argPathRatio',\n",
       " 'domainUrlRatio',\n",
       " 'ldl_domain',\n",
       " 'SymbolCount_Afterpath',\n",
       " 'NumberofDotsinURL',\n",
       " 'host_DigitCount',\n",
       " 'Path_LongestWordLength',\n",
       " 'dld_path',\n",
       " 'dld_getArg',\n",
       " 'SymbolCount_FileName',\n",
       " 'URLQueries_variable',\n",
       " 'tld',\n",
       " 'charcompace',\n",
       " 'Extension_DigitCount',\n",
       " 'isPortEighty',\n",
       " 'NumberRate_DirectoryName',\n",
       " 'ldl_filename',\n",
       " 'ldl_path',\n",
       " 'File_name_DigitCount',\n",
       " 'urlLen',\n",
       " 'sub-Directory_LongestWordLength',\n",
       " 'delimeter_Domain',\n",
       " 'Querylength',\n",
       " 'NumberRate_Domain',\n",
       " 'fileNameLen',\n",
       " 'delimeter_path',\n",
       " 'ArgLen',\n",
       " 'NumberRate_Extension',\n",
       " 'spcharUrl',\n",
       " 'Query_LetterCount',\n",
       " 'dld_filename',\n",
       " 'argDomanRatio',\n",
       " 'pathurlRatio',\n",
       " 'Directory_DigitCount',\n",
       " 'ldl_getArg',\n",
       " 'Entropy_URL',\n",
       " 'Entropy_Domain',\n",
       " 'Entropy_Filename',\n",
       " 'Filename_LetterCount',\n",
       " 'pathLength',\n",
       " 'charcompvowels',\n",
       " 'Entropy_Extension',\n",
       " 'Entropy_DirectoryName',\n",
       " 'delimeter_Count',\n",
       " 'dld_domain',\n",
       " 'subDirLen',\n",
       " 'domainlength',\n",
       " 'CharacterContinuityRate',\n",
       " 'path_token_count',\n",
       " 'NumberRate_FileName',\n",
       " 'avgdomaintokenlen',\n",
       " 'domain_token_count',\n",
       " 'SymbolCount_Domain',\n",
       " 'host_letter_count',\n",
       " 'ISIpAddressInDomainName',\n",
       " 'LongestPathTokenLength',\n",
       " 'Entropy_Afterpath',\n",
       " 'executable',\n",
       " 'SymbolCount_Extension',\n",
       " 'Domain_LongestWordLength',\n",
       " 'NumberRate_URL']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.07692308\n",
       "1         0.05882353\n",
       "2        0.060606062\n",
       "3        0.025974026\n",
       "4        0.040816326\n",
       "5        0.033898305\n",
       "6        0.046511628\n",
       "7               0.04\n",
       "8        0.045454547\n",
       "9         0.09090909\n",
       "10        0.04347826\n",
       "11       0.039215688\n",
       "12         0.0952381\n",
       "13        0.10526316\n",
       "14              0.08\n",
       "15        0.08695652\n",
       "16        0.03846154\n",
       "17       0.083333336\n",
       "18        0.01724138\n",
       "19       0.016949153\n",
       "20       0.020408163\n",
       "21       0.012578616\n",
       "22       0.014814815\n",
       "23       0.014084507\n",
       "24            0.0125\n",
       "25       0.018181818\n",
       "26              0.05\n",
       "27       0.037037037\n",
       "28       0.039215688\n",
       "29       0.036363635\n",
       "            ...     \n",
       "36677      0.7925926\n",
       "36678     0.76363635\n",
       "36679      0.7941176\n",
       "36680       0.015625\n",
       "36681    0.057142857\n",
       "36682     0.08510638\n",
       "36683      0.6626506\n",
       "36684            0.1\n",
       "36685      0.4074074\n",
       "36686    0.036363635\n",
       "36687       0.578125\n",
       "36688     0.12941177\n",
       "36689      0.7126437\n",
       "36690     0.78504676\n",
       "36691     0.08695652\n",
       "36692           0.04\n",
       "36693     0.06896552\n",
       "36694      0.7425743\n",
       "36695    0.015267176\n",
       "36696    0.071428575\n",
       "36697      0.9853862\n",
       "36698      0.8173077\n",
       "36699          0.275\n",
       "36700     0.05263158\n",
       "36701     0.10526316\n",
       "36702      0.7522124\n",
       "36703    0.016393442\n",
       "36704     0.83870965\n",
       "36705      0.7553192\n",
       "36706     0.82828283\n",
       "Name: argPathRatio, Length: 36697, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['argPathRatio'] # was reading as object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.argPathRatio = df['argPathRatio'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(feature_layer,inputDim=-1):\n",
    "    global model_name\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_layer,\n",
    "        Dense(128, activation='relu', input_shape=(inputDim,)),\n",
    "    #print(f\"out_shape[1]:{out_shape[1]}\")\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='softmax')\n",
    "    ]) #This is the output layer\n",
    "\n",
    "    print('Categorical Cross-Entropy Loss Function')\n",
    "    model_name += \"_categorical\"\n",
    "    model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "#         else:\n",
    "#             model_name += \"_binary\"\n",
    "#             print('Binary Cross-Entropy Loss Function')\n",
    "#             model.compile(optimizer='adam',\n",
    "#                     loss='binary_crossentropy',\n",
    "#                     metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0710 13:17:49.870158 140038712104576 deprecation.py:506] From /usr/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: adam epochs: 10 batch_size: 32\n",
      "[ 0.00000000e+00  4.00000000e+00  5.00000000e+00  5.50000000e+00\n",
      "  1.40000000e+01  4.40000000e+00  4.00000000e+00  8.00000000e+00\n",
      "  3.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.80000000e+01\n",
      "  2.50000000e+01  2.60000000e+01  2.60000000e+01  1.30000000e+01\n",
      "  1.00000000e+00  2.00000000e+00  4.48275860e-01  3.44827600e-02\n",
      "  8.00000000e-02  4.31034480e-01  1.04000000e+00  7.69230800e-02\n",
      "  0.00000000e+00 -1.00000000e+00  5.00000000e+00 -1.00000000e+00\n",
      "  6.00000000e-01 -1.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.00000000e+00 -1.00000000e+00\n",
      "  4.70000000e+01  2.20000000e+01  8.00000000e+00  1.30000000e+01\n",
      "  0.00000000e+00 -1.00000000e+00  1.30000000e+01  1.40000000e+01\n",
      "  1.30000000e+01  5.00000000e+00 -1.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  3.00000000e+00  0.00000000e+00  2.00000000e+00\n",
      " -1.00000000e+00  1.72413793e-02  0.00000000e+00  0.00000000e+00\n",
      "  6.66666667e-02  1.00000000e+00 -1.00000000e+00  8.00000000e+00\n",
      "  3.00000000e+00  2.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.00000000e+00  7.26298195e-01  7.84493326e-01  8.94885518e-01\n",
      "  8.50607752e-01             nan -1.00000000e+00]\n",
      "inputdim =  79\n",
      "Categorical Cross-Entropy Loss Function\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Cast string to float is not supported\n\t [[{{node Cast_79}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-48c9ae4478aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;31m#print(\"Training \" + dataFile + \" on split \" + str(num))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m#model.fit(x=X_train, y=y_train, epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[tensorboard], validation_data=(X_test, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;31m#save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}.model'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m           \u001b[0;31m# `ins` can be callable in tf.distribute.Strategy + eager case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m           \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3287\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m         session != self._session):\n\u001b[0;32m-> 3289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   3220\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m     \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3222\u001b[0;31m     \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3223\u001b[0m     \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m     \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \"\"\"\n\u001b[1;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1444\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1446\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1447\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Cast string to float is not supported\n\t [[{{node Cast_79}}]]"
     ]
    }
   ],
   "source": [
    "optimizer='adam'\n",
    "epochs=10\n",
    "batch_size=10\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['dld_getArg',\n",
    " 'URLQueries_variable',\n",
    " 'Directory_DigitCount',\n",
    " 'domainUrlRatio',\n",
    " 'Entropy_Extension',\n",
    " 'tld',\n",
    " 'path_token_count',\n",
    " 'pathDomainRatio',\n",
    " 'charcompace',\n",
    " 'File_name_DigitCount',\n",
    " 'SymbolCount_Afterpath',\n",
    " 'Arguments_LongestWordLength',\n",
    " 'this.fileExtLen',\n",
    " 'NumberRate_Extension',\n",
    " 'ldl_url',\n",
    " 'Filename_LetterCount',\n",
    " 'executable',\n",
    " 'NumberRate_URL',\n",
    " 'Entropy_Filename',\n",
    " 'dld_url',\n",
    " 'Querylength',\n",
    " 'CharacterContinuityRate',\n",
    " 'Entropy_DirectoryName',\n",
    " 'ldl_getArg',\n",
    " 'NumberRate_FileName',\n",
    " 'fileNameLen',\n",
    " 'Extension_LetterCount',\n",
    " 'SymbolCount_URL',\n",
    " 'NumberRate_AfterPath',\n",
    " 'delimeter_Domain',\n",
    " 'avgdomaintokenlen',\n",
    " 'domain_token_count',\n",
    " 'Extension_DigitCount',\n",
    " 'Directory_LetterCount',\n",
    " 'URL_DigitCount',\n",
    " 'charcompvowels',\n",
    " 'Query_LetterCount',\n",
    " 'ldl_domain',\n",
    " 'SymbolCount_FileName',\n",
    " 'ISIpAddressInDomainName',\n",
    " 'ArgLen',\n",
    " 'isPortEighty',\n",
    " 'host_letter_count',\n",
    " 'subDirLen',\n",
    " 'dld_path',\n",
    " 'Entropy_Domain',\n",
    " 'pathLength',\n",
    " 'Entropy_Afterpath',\n",
    " 'domainlength',\n",
    " 'ArgUrlRatio',\n",
    " 'Query_DigitCount',\n",
    " 'dld_domain',\n",
    " 'longdomaintokenlen',\n",
    " 'sub-Directory_LongestWordLength',\n",
    " 'pathurlRatio',\n",
    " 'dld_filename',\n",
    " 'NumberRate_DirectoryName',\n",
    " 'ldl_filename',\n",
    " 'Path_LongestWordLength',\n",
    " 'SymbolCount_Domain',\n",
    " 'LongestVariableValue',\n",
    " 'Entropy_URL',\n",
    " 'Domain_LongestWordLength',\n",
    " 'argPathRatio',\n",
    " 'NumberRate_Domain',\n",
    " 'ldl_path',\n",
    " 'urlLen',\n",
    " 'delimeter_path',\n",
    " 'SymbolCount_Extension',\n",
    " 'avgpathtokenlen',\n",
    " 'NumberofDotsinURL',\n",
    " 'delimeter_Count',\n",
    " 'argDomanRatio',\n",
    " 'LongestPathTokenLength',\n",
    " 'URL_sensitiveWord',\n",
    " 'spcharUrl',\n",
    " 'URL_Letter_Count',\n",
    " 'SymbolCount_Directoryname',\n",
    " 'host_DigitCount']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop(dep_var)\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds\n",
    "\n",
    "batch_size = 32 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    \n",
    "#Creating data for analysis\n",
    "time_gen = int(time.time())\n",
    "global model_name\n",
    "model_name = f\"{dataFile}_{time_gen}\"\n",
    "#$ tensorboard --logdir=logs/\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(model_name))\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "cvscores = []\n",
    "print('optimizer: {} epochs: {} batch_size: {}'.format(\n",
    "    optimizer, epochs, batch_size))\n",
    "\n",
    "data_y = df.pop(dep_var)\n",
    "\n",
    "#transform named labels into numerical values\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.fit(data_y)\n",
    "# data_y = encoder.transform(data_y)\n",
    "# dummy_y = to_categorical(data_y)\n",
    "data_x = df.values\n",
    "\n",
    "print(data_x[0])\n",
    "\n",
    "#define 5-fold cross validation test harness\n",
    "inputDim = len(data_x[0])\n",
    "print('inputdim = ', inputDim)\n",
    "\n",
    "#Separate out data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data_x, dummy_y, test_size=0.2)\n",
    "#num=0\n",
    "#for train_index, test_index in sss.split(np.zeros(data_x.shape[0]), dummy_y):\n",
    "    \n",
    "    #X_train, X_test = data_x[train_index], data_x[test_index]\n",
    "    #y_train, y_test = dummy_y[train_index], dummy_y[test_index]\n",
    "\n",
    "    #create model\n",
    "model = baseline_model(feature_layer, inputDim)\n",
    "\n",
    "    #train\n",
    "#print(\"Training \" + dataFile + \" on split \" + str(num))\n",
    "#model.fit(x=X_train, y=y_train, epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[tensorboard], validation_data=(X_test, y_test))\n",
    "model.fit(train_ds, validation_data=val_ds,epochs=epochs)\n",
    "#save model\n",
    "model.save('{}.model'.format(os.path.basename(dataPath)))\n",
    "\n",
    "#num+=1\n",
    "\n",
    "\n",
    "scores = model.evaluate(test_ds, verbose=1)\n",
    "print(model.metrics_names)\n",
    "acc, loss = scores[1]*100, scores[0]*100\n",
    "print('Baseline: accuracy: {:.2f}%: loss: {:.2f}'.format(acc, loss))\n",
    "\n",
    "resultFile = os.path.join(resultPath, 'All.csv')\n",
    "with open('{}.result'.format(resultFile), 'a') as fout:\n",
    "    fout.write('{} results...'.format(model_name))\n",
    "    fout.write('\\taccuracy: {:.2f} loss: {:.2f}\\n'.format(acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y, losses = model.get_preds(with_loss=True)\n",
    "interp = ClassificationInterpretation(model, preds, y, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(slice_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interp.confusion_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
