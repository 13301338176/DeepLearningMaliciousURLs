{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-Tensorflow-Experiments.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rambasnet/DeepLearningMaliciousURLs/blob/master/Keras-Tensorflow-Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SFAQJfeWplvv"
      },
      "source": [
        "# Keras-Tensorflow Experiments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CQ6Ngesk0F9d"
      },
      "source": [
        "##### Sources:\n",
        " + https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\n",
        " + https://www.kaggle.com/grafiszti/98-59-acc-on-10-fold-with-testing-7-keras-models\n",
        " + https://keras.io/visualization/\n",
        " + https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "47GgPW0G0Pi7"
      },
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GbTWr3JeuzLm"
      },
      "source": [
        "### Include needed files. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sBMU4MElu9GB",
        "outputId": "a0788077-d17d-4025-cd06-73764a28bf9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import operator\n",
        "import time\n",
        "\n",
        "import seaborn as sn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils.np_utils import to_categorical, normalize\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07jwatic7-Jk"
      },
      "source": [
        "### Include Dataset\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ngdiiVOJ8Bt4",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "URL=https://iscxdownloads.cs.unb.ca/iscxdownloads/ISCX-URL-2016/\n",
        "FILES=(ISCXURL2016.zip) \n",
        "for FILE in ${FILES[*]}; do\n",
        "    if [ ! -f \"$FILE\" ]; then\n",
        "        printf \"downloading %s\\n\" $FILE\n",
        "        curl -O $URL$FILE\n",
        "        # unzip files\n",
        "        echo 'unzipping ' $FILE\n",
        "        unzip -o $FILE #overwrite exiting files/folders if exists\n",
        "    fi\n",
        "done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MIqy2Xmc8HoD"
      },
      "source": [
        "### Check Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zl2T8MRq8PNT",
        "outputId": "740ada9c-0a95-438d-a434-44785e61efc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "! ls FinalDataset"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All_BestFirst.csv\t      Malware_Infogain.csv\n",
            "All_BestFirst_test.csv\t      Malware_Infogain_test.csv\n",
            "All.csv\t\t\t      Phishing_BestFirst.csv\n",
            "All.csv.pickle\t\t      Phishing.csv\n",
            "All_Infogain.csv\t      Phishing_Infogain.csv\n",
            "All_Infogain_test.csv\t      Phishing_Infogain_test.csv\n",
            "Defacement_BestFirst.csv      Spam_BestFirst.csv\n",
            "Defacement.csv\t\t      Spam_BestFirst_test.csv\n",
            "Defacement_Infogain.csv       Spam.csv\n",
            "Defacement_Infogain_test.csv  Spam_Infogain.csv\n",
            "Malware_BestFirst.csv\t      Spam_Infogain_test.csv\n",
            "Malware.csv\t\t      URL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IeCm3LP08XOy"
      },
      "source": [
        "### Set some data\n",
        "> Some data needs to be set, we need to ensure that constants are set properly. These are important but will not be used until later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qJuZTgd0u_WG",
        "colab": {}
      },
      "source": [
        "resultPath = 'results_keras_tensorflow'\n",
        "if not os.path.exists(resultPath):\n",
        "   print('result path {} created.'.format(resultPath))\n",
        "   os.mkdir(resultPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EHnzBhcavSR-",
        "colab": {}
      },
      "source": [
        "model_name = \"init\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vo0Cwne9wRJ"
      },
      "source": [
        "## Functions for Testing\n",
        "> Now that our data has been collected it is time to create functions that will be used in later tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DFtoJCs_7T8p",
        "colab": {}
      },
      "source": [
        "def loadData(csvFile):\n",
        "    pickleDump = '{}.pickle'.format(csvFile)\n",
        "    if os.path.exists(pickleDump):\n",
        "        df = pd.read_pickle(pickleDump)\n",
        "    else:\n",
        "        df = pd.read_csv(csvFile, low_memory=False, na_values='NaN')\n",
        "        # clean data\n",
        "        # strip the whitspaces from column names\n",
        "        df = df.rename(str.strip, axis='columns')\n",
        "        #df.drop(columns=[], inplace=True)\n",
        "        # drop missing values/NaN etc.\n",
        "        #df.dropna(inplace=True)\n",
        "        # drop Infinity rows and NaN string from each column\n",
        "        for col in df.columns:\n",
        "            indexNames = df[df[col]=='Infinity'].index\n",
        "            if not indexNames.empty:\n",
        "                print('deleting {} rows with Infinity in column {}'.format(len(indexNames), col))\n",
        "                df.drop(indexNames, inplace=True)\n",
        "        \n",
        "        df.to_pickle(pickleDump)\n",
        "    \n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GB51N0iLCK9J",
        "colab": {}
      },
      "source": [
        "def baseline_model(inputDim=-1,outputDim=-1):\n",
        "    global model_extension, experimentTitle\n",
        "    model = tf.keras.Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(inputDim,)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(.5),\n",
        "        Dense(outputDim, activation='softmax')\n",
        "    ]) #This is the output layer\n",
        "\n",
        "    if outputDim > 2:\n",
        "        print('Categorical Cross-Entropy Loss Function')\n",
        "        model_extension = \"_categorical\"\n",
        "        experimentTitle = \"Categorical\"\n",
        "        model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    else:\n",
        "        print('Binary Cross-Entropy Loss Function')\n",
        "        model_extension = \"_binary\"\n",
        "        experimentTitle = \"Binary\"\n",
        "        model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zbiT-Sf9plwd",
        "colab": {}
      },
      "source": [
        "def encode_labels(dataframe):\n",
        "    dataframe=dataframe.copy()\n",
        "    data_y=dataframe.pop(dep_var)\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(data_y)\n",
        "    data_y = encoder.transform(data_y)\n",
        "    dummy_y = to_categorical(data_y)\n",
        "    return dummy_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3aQvhWPU1H8v",
        "colab": {}
      },
      "source": [
        "def plotAccuracy(title):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCdjh6ZY--2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotLoss(title):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U1bG2p566m8V",
        "colab": {}
      },
      "source": [
        "# Function to determine train and validation indexes, \n",
        "# and fit the data to the model we constructed\n",
        "def experiment(dataframe, early=False):\n",
        "    \n",
        "    #10-fold cross validation, choosing random indices for training and validation\n",
        "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    \n",
        "    # Encode the label column for model fitting\n",
        "    encoded_y = dataframe.copy()\n",
        "    encoded_y = encode_labels(encoded_y)\n",
        "    \n",
        "    # X is our data/features to train the model with\n",
        "    X=StandardScaler().fit_transform(dataframe.drop(dep_var, axis=1))\n",
        "    \n",
        "    # Y is our labels to classify the data\n",
        "    y=LabelEncoder().fit_transform(dataframe[dep_var].values)\n",
        "    start_time = time.time()\n",
        "\n",
        "    for index, (train_indices, val_indices) in enumerate(kfold.split(X, y)):\n",
        "        \n",
        "        xtrain, xval = X[train_indices], X[val_indices]\n",
        "        ytrain, yval = encoded_y[train_indices], encoded_y[val_indices]\n",
        "\n",
        "        inputDim=xtrain.shape[1]\n",
        "        outputDim=ytrain.shape[1]\n",
        "        print(\"Running fold #\" + str(index+1))\n",
        "\n",
        "        model = baseline_model(inputDim,outputDim)\n",
        "        \n",
        "        time_gen = int(time.time())\n",
        "        \n",
        "        global model_name\n",
        "        model_name = f\"{dataFile}_{time_gen}\"\n",
        "\n",
        "        tensorboard = TensorBoard(log_dir='keras_tensorflow_logs/{}/{}_{}'.format(experimentTitle, model_name, model_extension),update_freq='epoch')\n",
        "        if early_stop:\n",
        "            callbacks = [tensorboard, early_stop]\n",
        "        else:\n",
        "            callbacks = [tensorboard]\n",
        "        history = model.fit(xtrain, ytrain, epochs=epochs, validation_data=(xval,yval), callbacks=callbacks, batch_size=batch_size, verbose=0)\n",
        "        \n",
        "    global end_time \n",
        "    end_time = time.time() - start_time\n",
        "    remain_seconds = 60%end_time\n",
        " \n",
        "    global Minutes \n",
        "    Minutes = int(end_time/60)\n",
        "    print(\"Time to complete {} min {} sec\".format(Minutes, end_time))\n",
        "        \n",
        "    return model, history, X, encoded_y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GkZ-uZuz9_pi"
      },
      "source": [
        "## Data\n",
        "### Load and Clean\n",
        "> First we will load our data, scan the columns for Infinity and NaN values, and remove those columns from testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h_7Y2Ytp7xa-",
        "colab": {}
      },
      "source": [
        "df1 = loadData('FinalDataset/All.csv')\n",
        "df1=df1.dropna(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mekPFv6lplwm"
      },
      "source": [
        "### Display Data Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4ZwM-GC1-LPj",
        "outputId": "e8fd409e-494f-466c-feda-615b96f83622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "df1.columns"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Querylength', 'domain_token_count', 'path_token_count',\n",
              "       'avgdomaintokenlen', 'longdomaintokenlen', 'tld', 'charcompvowels',\n",
              "       'charcompace', 'ldl_url', 'ldl_domain', 'ldl_path', 'ldl_filename',\n",
              "       'ldl_getArg', 'dld_url', 'dld_domain', 'dld_path', 'dld_filename',\n",
              "       'dld_getArg', 'urlLen', 'domainlength', 'pathLength', 'subDirLen',\n",
              "       'fileNameLen', 'this.fileExtLen', 'ArgLen', 'pathurlRatio',\n",
              "       'ArgUrlRatio', 'argDomanRatio', 'domainUrlRatio', 'pathDomainRatio',\n",
              "       'argPathRatio', 'executable', 'isPortEighty', 'NumberofDotsinURL',\n",
              "       'ISIpAddressInDomainName', 'CharacterContinuityRate',\n",
              "       'LongestVariableValue', 'URL_DigitCount', 'host_DigitCount',\n",
              "       'Directory_DigitCount', 'File_name_DigitCount', 'Extension_DigitCount',\n",
              "       'Query_DigitCount', 'URL_Letter_Count', 'host_letter_count',\n",
              "       'Directory_LetterCount', 'Filename_LetterCount',\n",
              "       'Extension_LetterCount', 'Query_LetterCount', 'LongestPathTokenLength',\n",
              "       'Domain_LongestWordLength', 'Path_LongestWordLength',\n",
              "       'sub-Directory_LongestWordLength', 'Arguments_LongestWordLength',\n",
              "       'URL_sensitiveWord', 'URLQueries_variable', 'spcharUrl',\n",
              "       'delimeter_Domain', 'delimeter_path', 'delimeter_Count',\n",
              "       'NumberRate_URL', 'NumberRate_Domain', 'NumberRate_DirectoryName',\n",
              "       'NumberRate_FileName', 'SymbolCount_URL', 'SymbolCount_Domain',\n",
              "       'SymbolCount_Directoryname', 'SymbolCount_FileName',\n",
              "       'SymbolCount_Extension', 'SymbolCount_Afterpath', 'Entropy_URL',\n",
              "       'Entropy_Domain', 'URL_Type_obf_Type'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wX24a-Woplwt"
      },
      "source": [
        "### Display Matrix Shape of Data\n",
        "> In the format (samples, columns)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NBvgfW-J--g8",
        "outputId": "232cac72-29fb-4cfe-a907-0d4277533cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df1.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36697, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BSjQXVYKplw0"
      },
      "source": [
        "### Display First Samples in Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9eYtvDf5AAR5",
        "outputId": "b97f9372-8cff-42f3-88b4-06ddfc32ad6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Querylength</th>\n",
              "      <th>domain_token_count</th>\n",
              "      <th>path_token_count</th>\n",
              "      <th>avgdomaintokenlen</th>\n",
              "      <th>longdomaintokenlen</th>\n",
              "      <th>tld</th>\n",
              "      <th>charcompvowels</th>\n",
              "      <th>charcompace</th>\n",
              "      <th>ldl_url</th>\n",
              "      <th>ldl_domain</th>\n",
              "      <th>ldl_path</th>\n",
              "      <th>ldl_filename</th>\n",
              "      <th>ldl_getArg</th>\n",
              "      <th>dld_url</th>\n",
              "      <th>dld_domain</th>\n",
              "      <th>dld_path</th>\n",
              "      <th>dld_filename</th>\n",
              "      <th>dld_getArg</th>\n",
              "      <th>urlLen</th>\n",
              "      <th>domainlength</th>\n",
              "      <th>pathLength</th>\n",
              "      <th>subDirLen</th>\n",
              "      <th>fileNameLen</th>\n",
              "      <th>this.fileExtLen</th>\n",
              "      <th>ArgLen</th>\n",
              "      <th>pathurlRatio</th>\n",
              "      <th>ArgUrlRatio</th>\n",
              "      <th>argDomanRatio</th>\n",
              "      <th>domainUrlRatio</th>\n",
              "      <th>pathDomainRatio</th>\n",
              "      <th>argPathRatio</th>\n",
              "      <th>executable</th>\n",
              "      <th>isPortEighty</th>\n",
              "      <th>NumberofDotsinURL</th>\n",
              "      <th>ISIpAddressInDomainName</th>\n",
              "      <th>CharacterContinuityRate</th>\n",
              "      <th>LongestVariableValue</th>\n",
              "      <th>URL_DigitCount</th>\n",
              "      <th>host_DigitCount</th>\n",
              "      <th>Directory_DigitCount</th>\n",
              "      <th>File_name_DigitCount</th>\n",
              "      <th>Extension_DigitCount</th>\n",
              "      <th>Query_DigitCount</th>\n",
              "      <th>URL_Letter_Count</th>\n",
              "      <th>host_letter_count</th>\n",
              "      <th>Directory_LetterCount</th>\n",
              "      <th>Filename_LetterCount</th>\n",
              "      <th>Extension_LetterCount</th>\n",
              "      <th>Query_LetterCount</th>\n",
              "      <th>LongestPathTokenLength</th>\n",
              "      <th>Domain_LongestWordLength</th>\n",
              "      <th>Path_LongestWordLength</th>\n",
              "      <th>sub-Directory_LongestWordLength</th>\n",
              "      <th>Arguments_LongestWordLength</th>\n",
              "      <th>URL_sensitiveWord</th>\n",
              "      <th>URLQueries_variable</th>\n",
              "      <th>spcharUrl</th>\n",
              "      <th>delimeter_Domain</th>\n",
              "      <th>delimeter_path</th>\n",
              "      <th>delimeter_Count</th>\n",
              "      <th>NumberRate_URL</th>\n",
              "      <th>NumberRate_Domain</th>\n",
              "      <th>NumberRate_DirectoryName</th>\n",
              "      <th>NumberRate_FileName</th>\n",
              "      <th>SymbolCount_URL</th>\n",
              "      <th>SymbolCount_Domain</th>\n",
              "      <th>SymbolCount_Directoryname</th>\n",
              "      <th>SymbolCount_FileName</th>\n",
              "      <th>SymbolCount_Extension</th>\n",
              "      <th>SymbolCount_Afterpath</th>\n",
              "      <th>Entropy_URL</th>\n",
              "      <th>Entropy_Domain</th>\n",
              "      <th>URL_Type_obf_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5.5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.431034</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0.07692308</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>47</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.726298</td>\n",
              "      <td>0.784493</td>\n",
              "      <td>Defacement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5.5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>25</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.515151</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.378788</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.05882353</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>56</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>-1</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.688635</td>\n",
              "      <td>0.784493</td>\n",
              "      <td>Defacement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5.5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>33</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.507692</td>\n",
              "      <td>0.030769</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.060606062</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>55</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>-1</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.695049</td>\n",
              "      <td>0.784493</td>\n",
              "      <td>Defacement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>5.5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>109</td>\n",
              "      <td>25</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.706422</td>\n",
              "      <td>0.018349</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.229358</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.025974026</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>92</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>45</td>\n",
              "      <td>-1</td>\n",
              "      <td>52</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.640130</td>\n",
              "      <td>0.784493</td>\n",
              "      <td>Defacement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5.5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>81</td>\n",
              "      <td>25</td>\n",
              "      <td>49</td>\n",
              "      <td>49</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.604938</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.308642</td>\n",
              "      <td>1.96</td>\n",
              "      <td>0.040816326</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>70</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>-1</td>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.681307</td>\n",
              "      <td>0.784493</td>\n",
              "      <td>Defacement</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Querylength  domain_token_count  ...  Entropy_Domain  URL_Type_obf_Type\n",
              "0            0                   4  ...        0.784493         Defacement\n",
              "1            0                   4  ...        0.784493         Defacement\n",
              "2            0                   4  ...        0.784493         Defacement\n",
              "3            0                   4  ...        0.784493         Defacement\n",
              "4            0                   4  ...        0.784493         Defacement\n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OLiGVjzOplw6"
      },
      "source": [
        "### Display Last Samples in Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LsqLE8Wnplw7",
        "outputId": "42645ee6-db49-4772-9efb-167d43789e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "df1.tail()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Querylength</th>\n",
              "      <th>domain_token_count</th>\n",
              "      <th>path_token_count</th>\n",
              "      <th>avgdomaintokenlen</th>\n",
              "      <th>longdomaintokenlen</th>\n",
              "      <th>tld</th>\n",
              "      <th>charcompvowels</th>\n",
              "      <th>charcompace</th>\n",
              "      <th>ldl_url</th>\n",
              "      <th>ldl_domain</th>\n",
              "      <th>ldl_path</th>\n",
              "      <th>ldl_filename</th>\n",
              "      <th>ldl_getArg</th>\n",
              "      <th>dld_url</th>\n",
              "      <th>dld_domain</th>\n",
              "      <th>dld_path</th>\n",
              "      <th>dld_filename</th>\n",
              "      <th>dld_getArg</th>\n",
              "      <th>urlLen</th>\n",
              "      <th>domainlength</th>\n",
              "      <th>pathLength</th>\n",
              "      <th>subDirLen</th>\n",
              "      <th>fileNameLen</th>\n",
              "      <th>this.fileExtLen</th>\n",
              "      <th>ArgLen</th>\n",
              "      <th>pathurlRatio</th>\n",
              "      <th>ArgUrlRatio</th>\n",
              "      <th>argDomanRatio</th>\n",
              "      <th>domainUrlRatio</th>\n",
              "      <th>pathDomainRatio</th>\n",
              "      <th>argPathRatio</th>\n",
              "      <th>executable</th>\n",
              "      <th>isPortEighty</th>\n",
              "      <th>NumberofDotsinURL</th>\n",
              "      <th>ISIpAddressInDomainName</th>\n",
              "      <th>CharacterContinuityRate</th>\n",
              "      <th>LongestVariableValue</th>\n",
              "      <th>URL_DigitCount</th>\n",
              "      <th>host_DigitCount</th>\n",
              "      <th>Directory_DigitCount</th>\n",
              "      <th>File_name_DigitCount</th>\n",
              "      <th>Extension_DigitCount</th>\n",
              "      <th>Query_DigitCount</th>\n",
              "      <th>URL_Letter_Count</th>\n",
              "      <th>host_letter_count</th>\n",
              "      <th>Directory_LetterCount</th>\n",
              "      <th>Filename_LetterCount</th>\n",
              "      <th>Extension_LetterCount</th>\n",
              "      <th>Query_LetterCount</th>\n",
              "      <th>LongestPathTokenLength</th>\n",
              "      <th>Domain_LongestWordLength</th>\n",
              "      <th>Path_LongestWordLength</th>\n",
              "      <th>sub-Directory_LongestWordLength</th>\n",
              "      <th>Arguments_LongestWordLength</th>\n",
              "      <th>URL_sensitiveWord</th>\n",
              "      <th>URLQueries_variable</th>\n",
              "      <th>spcharUrl</th>\n",
              "      <th>delimeter_Domain</th>\n",
              "      <th>delimeter_path</th>\n",
              "      <th>delimeter_Count</th>\n",
              "      <th>NumberRate_URL</th>\n",
              "      <th>NumberRate_Domain</th>\n",
              "      <th>NumberRate_DirectoryName</th>\n",
              "      <th>NumberRate_FileName</th>\n",
              "      <th>SymbolCount_URL</th>\n",
              "      <th>SymbolCount_Domain</th>\n",
              "      <th>SymbolCount_Directoryname</th>\n",
              "      <th>SymbolCount_FileName</th>\n",
              "      <th>SymbolCount_Extension</th>\n",
              "      <th>SymbolCount_Afterpath</th>\n",
              "      <th>Entropy_URL</th>\n",
              "      <th>Entropy_Domain</th>\n",
              "      <th>URL_Type_obf_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36702</th>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>5.750000</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>26</td>\n",
              "      <td>113</td>\n",
              "      <td>113</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>85</td>\n",
              "      <td>0.773973</td>\n",
              "      <td>0.582192</td>\n",
              "      <td>3.269231</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>4.346154</td>\n",
              "      <td>0.7522124</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>23</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>94</td>\n",
              "      <td>23</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>14</td>\n",
              "      <td>24</td>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0.212329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0.690555</td>\n",
              "      <td>0.791265</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36703</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>147</td>\n",
              "      <td>18</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.829932</td>\n",
              "      <td>0.013605</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>6.777778</td>\n",
              "      <td>0.016393442</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-1</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>-1</td>\n",
              "      <td>101</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>69</td>\n",
              "      <td>-1</td>\n",
              "      <td>105</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.665492</td>\n",
              "      <td>0.820010</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36704</th>\n",
              "      <td>58</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>6.666666</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>34</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>246</td>\n",
              "      <td>22</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>182</td>\n",
              "      <td>0.882114</td>\n",
              "      <td>0.739837</td>\n",
              "      <td>8.272727</td>\n",
              "      <td>0.089431</td>\n",
              "      <td>9.863636</td>\n",
              "      <td>0.83870965</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>7</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>58</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>20</td>\n",
              "      <td>71</td>\n",
              "      <td>3</td>\n",
              "      <td>58</td>\n",
              "      <td>48</td>\n",
              "      <td>118</td>\n",
              "      <td>16</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.231707</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.377778</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>0.656807</td>\n",
              "      <td>0.801139</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36705</th>\n",
              "      <td>35</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>4.333334</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>116</td>\n",
              "      <td>15</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>71</td>\n",
              "      <td>0.810345</td>\n",
              "      <td>0.612069</td>\n",
              "      <td>4.733333</td>\n",
              "      <td>0.129310</td>\n",
              "      <td>6.266667</td>\n",
              "      <td>0.7553192</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>32</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>23</td>\n",
              "      <td>73</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>41</td>\n",
              "      <td>12</td>\n",
              "      <td>75</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.215517</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.284091</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0.725963</td>\n",
              "      <td>0.897617</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36706</th>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>6.666666</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>227</td>\n",
              "      <td>22</td>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>0.872247</td>\n",
              "      <td>0.722467</td>\n",
              "      <td>7.454546</td>\n",
              "      <td>0.096916</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.82828283</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.772727</td>\n",
              "      <td>40</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>144</td>\n",
              "      <td>20</td>\n",
              "      <td>50</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>31</td>\n",
              "      <td>118</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.229075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.365079</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>0.674351</td>\n",
              "      <td>0.801139</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Querylength  domain_token_count  ...  Entropy_Domain  URL_Type_obf_Type\n",
              "36702           29                   4  ...        0.791265               spam\n",
              "36703            0                   4  ...        0.820010               spam\n",
              "36704           58                   3  ...        0.801139               spam\n",
              "36705           35                   3  ...        0.897617               spam\n",
              "36706           40                   3  ...        0.801139               spam\n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f2zcKS_DAGcx"
      },
      "source": [
        "  ## Experimenting with Final Dataset/All.csv\n",
        "  \n",
        "  #### Total Samples for each Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NuFeBCWJABj9",
        "outputId": "c4773bb2-a1e9-4511-8314-d06f0431c0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "label = 'URL_Type_obf_Type'\n",
        "lblTypes=set(df1[label])\n",
        "for lbl in lblTypes:\n",
        "    print('| {} | {} |'.format(lbl, len(df1[df1[label] == lbl].index)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Defacement | 7930 |\n",
            "| malware | 6711 |\n",
            "| benign | 7781 |\n",
            "| phishing | 7577 |\n",
            "| spam | 6698 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KlTOWuf8A_Yy",
        "colab": {}
      },
      "source": [
        "dataPath = 'FinalDataset'\n",
        "dep_var = label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B1keV97eplxW"
      },
      "source": [
        "### Cast column values to float\n",
        "> Values in this column register as object type, which isn't valid for testing, so cast them to float"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2nFBzqafCKkG",
        "colab": {}
      },
      "source": [
        "df1.argPathRatio = df1['argPathRatio'].astype('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaUqSRUiItig"
      },
      "source": [
        "## Experimenting with Tensorflow Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4c-GxIVIIZAR"
      },
      "source": [
        "#### Globals for Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x-fMOCE2I7MI",
        "colab": {}
      },
      "source": [
        "dataFile = 'All.csv'\n",
        "epochs=100\n",
        "batch_size=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mxNlAPk2plxh"
      },
      "source": [
        "#### Show uncoded label column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZfKJek8splxi",
        "outputId": "5ade0d95-30c3-408d-9d22-8a6d61cd5b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df1[dep_var]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Defacement\n",
              "1        Defacement\n",
              "2        Defacement\n",
              "3        Defacement\n",
              "4        Defacement\n",
              "5        Defacement\n",
              "6        Defacement\n",
              "7        Defacement\n",
              "8        Defacement\n",
              "9        Defacement\n",
              "10       Defacement\n",
              "11       Defacement\n",
              "12       Defacement\n",
              "13       Defacement\n",
              "14       Defacement\n",
              "15       Defacement\n",
              "16       Defacement\n",
              "17       Defacement\n",
              "18       Defacement\n",
              "19       Defacement\n",
              "20       Defacement\n",
              "21       Defacement\n",
              "22       Defacement\n",
              "23       Defacement\n",
              "24       Defacement\n",
              "25       Defacement\n",
              "26       Defacement\n",
              "27       Defacement\n",
              "28       Defacement\n",
              "29       Defacement\n",
              "            ...    \n",
              "36677          spam\n",
              "36678          spam\n",
              "36679          spam\n",
              "36680          spam\n",
              "36681          spam\n",
              "36682          spam\n",
              "36683          spam\n",
              "36684          spam\n",
              "36685          spam\n",
              "36686          spam\n",
              "36687          spam\n",
              "36688          spam\n",
              "36689          spam\n",
              "36690          spam\n",
              "36691          spam\n",
              "36692          spam\n",
              "36693          spam\n",
              "36694          spam\n",
              "36695          spam\n",
              "36696          spam\n",
              "36697          spam\n",
              "36698          spam\n",
              "36699          spam\n",
              "36700          spam\n",
              "36701          spam\n",
              "36702          spam\n",
              "36703          spam\n",
              "36704          spam\n",
              "36705          spam\n",
              "36706          spam\n",
              "Name: URL_Type_obf_Type, Length: 36697, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ikcFoxzcplxt"
      },
      "source": [
        "#### Random seed for splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "41We5rvNplxu",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZVQv1Yf--45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in glob.glob('keras_tensorflow_logs/Categorical*'):\n",
        "        if os.path.exists(file):\n",
        "            shutil.rmtree(file)\n",
        "for file in glob.glob('keras_tensorflow_logs/Binary*'):\n",
        "    if os.path.exists(file):\n",
        "        shutil.rmtree(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRIlEuMmDHbY",
        "colab_type": "text"
      },
      "source": [
        "### Overfitting and Underfitting\n",
        "We need to test the best way to avoid over/under-fitting. \n",
        "\n",
        "1. I want to setup an early stop using the Keras Function\n",
        "2. I want to give the models a full train to see overfitting/underfitting results for the base model.\n",
        "2. I will test Early Stop to prevent underfitting\n",
        "3. I will test Weight Regularization\n",
        "4. I will test a dropout\n",
        "\n",
        "> our goal is to train quickly and efficiently. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqrMvP79DOlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Constants for this\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "import datetime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUlPMdGoD3on",
        "colab_type": "text"
      },
      "source": [
        "* We will use the function experiment and edit it until the model is properly fitted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDdgkOumKUPL",
        "colab_type": "text"
      },
      "source": [
        "#### BaseLine Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz2Fc0ySKZH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TESTbaseline_model(inputDim=-1,outputDim=-1):\n",
        "    global model_extension, experimentTitle\n",
        "    model = tf.keras.Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(inputDim,)),\n",
        "        BatchNormalization(),\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dense(outputDim, activation='softmax')\n",
        "    ]) #This is the output layer\n",
        "\n",
        "    if outputDim > 2:\n",
        "        print('Categorical Cross-Entropy Loss Function')\n",
        "        model_extension = \"_categorical\"\n",
        "        experimentTitle = \"Categorical\"\n",
        "        model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    else:\n",
        "        print('Binary Cross-Entropy Loss Function')\n",
        "        model_extension = \"_binary\"\n",
        "        experimentTitle = \"Binary\"\n",
        "        model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "def Test1experiment(dataframe, early=False):\n",
        "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    encoded_y = dataframe.copy()\n",
        "    encoded_y = encode_labels(encoded_y)\n",
        "    X=StandardScaler().fit_transform(dataframe.drop(dep_var, axis=1))\n",
        "    y=LabelEncoder().fit_transform(dataframe[dep_var].values)\n",
        "    start_time = time.time()\n",
        "    for index, (train_indices, val_indices) in enumerate(kfold.split(X, y)):\n",
        "        xtrain, xval = X[train_indices], X[val_indices]\n",
        "        ytrain, yval = encoded_y[train_indices], encoded_y[val_indices]\n",
        "        inputDim=xtrain.shape[1]\n",
        "        outputDim=ytrain.shape[1]\n",
        "        print(\"Running fold #\" + str(index+1))\n",
        "        model = baseline_model(inputDim,outputDim)    \n",
        "        time_gen = int(time.time())        \n",
        "        global model_name\n",
        "        model_name = f\"{dataFile}_{time_gen}\"\n",
        "        tensorboard = TensorBoard(log_dir='keras_tensorflow_logs/{}/{}_{}'.format(experimentTitle, model_name, model_extension),update_freq='epoch')\n",
        "        if early_stop:\n",
        "            callbacks = [tensorboard]\n",
        "        else:\n",
        "            callbacks = [tensorboard]\n",
        "        history = model.fit(xtrain, ytrain, epochs=epochs, validation_data=(xval,yval), callbacks=callbacks, batch_size=batch_size, verbose=0)        \n",
        "    global end_time \n",
        "    end_time = time.time() - start_time\n",
        "    TimeSetup = str(datetime.timedelta(seconds=end_time))\n",
        "    Minutes = int(end_time/60)\n",
        "    print(\"Time to complete {} [hour:min:sec]\".format(TimeSetup))    \n",
        "    return model, history, X, encoded_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUw-9Oj_Ka6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_df = df1.copy()\n",
        "modelTest1, history, X , encoded_y = Test1experiment(categorical_df,early=True)\n",
        "plotLoss('Categorical Model Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePBe4eNCD3OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Test1experiment(dataframe, early=False):\n",
        "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "    encoded_y = dataframe.copy()\n",
        "    encoded_y = encode_labels(encoded_y)\n",
        "    X=StandardScaler().fit_transform(dataframe.drop(dep_var, axis=1))\n",
        "    y=LabelEncoder().fit_transform(dataframe[dep_var].values)\n",
        "    start_time = time.time()\n",
        "    for index, (train_indices, val_indices) in enumerate(kfold.split(X, y)):\n",
        "        xtrain, xval = X[train_indices], X[val_indices]\n",
        "        ytrain, yval = encoded_y[train_indices], encoded_y[val_indices]\n",
        "        inputDim=xtrain.shape[1]\n",
        "        outputDim=ytrain.shape[1]\n",
        "        print(\"Running fold #\" + str(index+1))\n",
        "        model = baseline_model(inputDim,outputDim)    \n",
        "        time_gen = int(time.time())        \n",
        "        global model_name\n",
        "        model_name = f\"{dataFile}_{time_gen}\"\n",
        "        tensorboard = TensorBoard(log_dir='keras_tensorflow_logs/{}/{}_{}'.format(experimentTitle, model_name, model_extension),update_freq='epoch')\n",
        "        if early_stop:\n",
        "            callbacks = [tensorboard]\n",
        "        else:\n",
        "            callbacks = [tensorboard]\n",
        "        history = model.fit(xtrain, ytrain, epochs=epochs, validation_data=(xval,yval), callbacks=callbacks, batch_size=batch_size, verbose=0)        \n",
        "    global end_time \n",
        "    end_time = time.time() - start_time\n",
        "    TimeSetup = str(datetime.timedelta(seconds=end_time))\n",
        "    Minutes = int(end_time/60)\n",
        "    print(\"Time to complete {} [hour:min:sec]\".format(TimeSetup))    \n",
        "    return model, history, X, encoded_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOUl3d7vERKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "7183c979-5127-4914-85b9-3edd1bd6bd26"
      },
      "source": [
        "categorical_df = df1.copy()\n",
        "modelTest1, history, X , encoded_y = Test1experiment(categorical_df,early=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running fold #1\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #2\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #3\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #4\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #5\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #6\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #7\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #8\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #9\n",
            "Categorical Cross-Entropy Loss Function\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS4DU8V7JI7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotLoss('Categorical Model Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QxvO-5wqplx1"
      },
      "source": [
        "### Run the experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wDKDVrhZplx2",
        "outputId": "3a13bf90-d631-4aa7-89b3-4e44b5afb3d8",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "categorical_df = df1.copy()\n",
        "model, history, X , encoded_y = experiment(categorical_df,early=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running fold #1\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #2\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #3\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #4\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #5\n",
            "Categorical Cross-Entropy Loss Function\n",
            "Running fold #6\n",
            "Categorical Cross-Entropy Loss Function\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-44fcbd99df02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcategorical_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoded_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-796704204103>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(dataframe, early)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# Callbacks batch_begin.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    253\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3495\u001b[0m     \"\"\"\n\u001b[1;32m   3496\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3497\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3499\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3403\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3405\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3512\u001b[0m         \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3514\u001b[0;31m         \u001b[0mszh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3515\u001b[0m         \u001b[0mkth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mszh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mszh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3516\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FoHKjaqpGQub"
      },
      "source": [
        "#### Save the model as a file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vixNeoaEGW9n",
        "colab": {}
      },
      "source": [
        "model.save('{}.model'.format(os.path.basename(dataPath)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R1VG5cxSplyA"
      },
      "source": [
        "### Model Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p3xvC6ZlG9Wz",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate(X,encoded_y, batch_size=batch_size,verbose=1)\n",
        "print(model.metrics_names)\n",
        "acc, loss = scores[1]*100, scores[0]\n",
        "print('Baseline: accuracy: {:.2f}%: loss: {:.2f}'.format(acc, loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hlNdQsyiplyF"
      },
      "source": [
        "#### Generate predictions from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a0jLyQXHplyG",
        "colab": {}
      },
      "source": [
        "prediction_y = model.predict_classes(X, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "44-OsF7tplyK"
      },
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xjsWSmWvplyM",
        "colab": {}
      },
      "source": [
        "y=LabelEncoder().fit_transform(categorical_df[dep_var].values)\n",
        "cm = confusion_matrix(y, prediction_y)\n",
        "sn.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Defacement','Benign','Malware','Phishing','Spam'],\n",
        "           yticklabels=['Defacement','Benign','Malware','Phishing','Spam'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UeVn3oV7plyQ"
      },
      "source": [
        "#### Graph of Categorical Cross-Entropy Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GzH_f_T3plyU",
        "colab": {}
      },
      "source": [
        "plotAccuracy('Categorical Model Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_hdnJn-I--5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotLoss('Categorical Model Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XtWNPIlMplyY"
      },
      "source": [
        "### Write results to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_YP-tODMplyZ",
        "colab": {}
      },
      "source": [
        "def saveLog():\n",
        "    resultFile = os.path.join(resultPath, dataFile)\n",
        "    with open('{}.result'.format(resultFile), 'a') as fout:\n",
        "        fout.write('{} results...'.format(model_name+model_extension))\n",
        "        fout.write('\\taccuracy: {:.2f} loss: {:.2f} time_elapsed: {} min {} sec\\n'.format(acc, loss, Minutes, end_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzeDeFBV--6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveLog()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aOJNLEDfplyc"
      },
      "source": [
        "## Binary Classification of Labels\n",
        "> Change all malicious labels to value 1 and benign label to 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QH5SPeyD1zUX"
      },
      "source": [
        "### Binarize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QzpGC1TYplyd",
        "colab": {}
      },
      "source": [
        "lblTypes = list(lblTypes)\n",
        "lblTypes = dict(zip(lblTypes, [1, 1, 1, 1, 1]))\n",
        "lblTypes['benign'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IQ5kYPnTplyg",
        "colab": {}
      },
      "source": [
        "binary_df = df1.copy()\n",
        "binary_df[label] = binary_df[label].map(lblTypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "taziMECuplyj"
      },
      "source": [
        "### Train the Binary Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "llXRdiQ1plyk",
        "colab": {}
      },
      "source": [
        "model, history, X , encoded_y = experiment(binary_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ta-ruG0K1eVN"
      },
      "source": [
        "### Model Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6FV5LefXplyt",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate(X,encoded_y, verbose=1)\n",
        "print(model.metrics_names)\n",
        "acc, loss = scores[1]*100, scores[0]\n",
        "print('Baseline: accuracy: {:.2f}%: loss: {:.2f}'.format(acc, loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DviMoEPX1hxZ"
      },
      "source": [
        "#### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0kU7Ncq7ply2",
        "colab": {}
      },
      "source": [
        "prediction_y = model.predict_classes(X, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0T2dZA9Nply8",
        "colab": {}
      },
      "source": [
        "y=LabelEncoder().fit_transform(binary_df[dep_var].values)\n",
        "cm = confusion_matrix(y, prediction_y)\n",
        "sn.heatmap(cm, cmap='Blues', annot=True, fmt='g', xticklabels=['Benign', 'Malicious'],\n",
        "        yticklabels=['Benign', 'Malicious'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4YdW3jb8plzB"
      },
      "source": [
        "#### Graph of Binary Cross-Entropy Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzeLN1BSplzC",
        "colab": {}
      },
      "source": [
        "plotAccuracy('Binary Model Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FObJJIn9--7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotLoss('Binary Model Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A8Il5_kL1oQt"
      },
      "source": [
        "### Write Results to File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qz6wRy6GplzH",
        "colab": {}
      },
      "source": [
        "saveLog()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-SU-b-6--7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}