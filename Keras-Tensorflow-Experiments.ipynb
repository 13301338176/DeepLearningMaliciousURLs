{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rambasnet/DeepLearningMaliciousURLs/blob/master/Keras_Tensorflow_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GbTWr3JeuzLm"
   },
   "source": [
    "# Include needed files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBMU4MElu9GB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import operator\n",
    "import time\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils.np_utils import to_categorical, normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07jwatic7-Jk"
   },
   "source": [
    "# Include Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngdiiVOJ8Bt4"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "URL=https://iscxdownloads.cs.unb.ca/iscxdownloads/ISCX-URL-2016/\n",
    "FILES=(ISCXURL2016.zip) \n",
    "for FILE in ${FILES[*]}; do\n",
    "    if [ ! -f \"$FILE\" ]; then\n",
    "        printf \"downloading %s\\n\" $FILE\n",
    "        curl -O $URL$FILE\n",
    "        # unzip files\n",
    "        echo 'unzipping ' $FILE\n",
    "        unzip -o $FILE #overwrite exiting files/folders if exists\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIqy2Xmc8HoD"
   },
   "source": [
    "### Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "zl2T8MRq8PNT",
    "outputId": "12105f44-7ad8-4d64-d0b5-c685a4368912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_BestFirst.csv\t      Malware_Infogain.csv\r\n",
      "All_BestFirst_test.csv\t      Malware_Infogain_test.csv\r\n",
      "All.csv\t\t\t      Phishing_BestFirst.csv\r\n",
      "All.csv.pickle\t\t      Phishing.csv\r\n",
      "All_Infogain.csv\t      Phishing_Infogain.csv\r\n",
      "All_Infogain_test.csv\t      Phishing_Infogain_test.csv\r\n",
      "Defacement_BestFirst.csv      Spam_BestFirst.csv\r\n",
      "Defacement.csv\t\t      Spam_BestFirst_test.csv\r\n",
      "Defacement_Infogain.csv       Spam.csv\r\n",
      "Defacement_Infogain_test.csv  Spam_Infogain.csv\r\n",
      "Malware_BestFirst.csv\t      Spam_Infogain_test.csv\r\n",
      "Malware.csv\t\t      URL\r\n"
     ]
    }
   ],
   "source": [
    "! ls FinalDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IeCm3LP08XOy"
   },
   "source": [
    "# Set some data\n",
    "> Some data needs to be set, we need to ensure that constants are set properly. These are important but will not be used until later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJuZTgd0u_WG"
   },
   "outputs": [],
   "source": [
    "resultPath = 'results_keras_tensorflow'\n",
    "if not os.path.exists(resultPath):\n",
    "   print('result path {} created.'.format(resultPath))\n",
    "   os.mkdir(resultPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHnzBhcavSR-"
   },
   "outputs": [],
   "source": [
    "dep_var = 'Label'\n",
    "model_name=\"init\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksQA_jwN7M_l"
   },
   "outputs": [],
   "source": [
    "cat_names = []\n",
    "cont_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "znNI_UOh8wP3"
   },
   "source": [
    "## Analyze FinalDataset/All.csv file\n",
    "> lets make sure that the files are properly added, this should look similar to the FASTAI experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzCPkRWQ85mq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('FinalDataset/All.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lTB52QcL9Bj0",
    "outputId": "b1b0fe5e-9e09-44ac-f523-f8e727790193"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36707, 80)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show all dataset column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "zl4B4wzz9Kie",
    "outputId": "0a40d848-a883-445e-9fab-332037fc2389"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Querylength', 'domain_token_count', 'path_token_count',\n",
       "       'avgdomaintokenlen', 'longdomaintokenlen', 'avgpathtokenlen', 'tld',\n",
       "       'charcompvowels', 'charcompace', 'ldl_url', 'ldl_domain', 'ldl_path',\n",
       "       'ldl_filename', 'ldl_getArg', 'dld_url', 'dld_domain', 'dld_path',\n",
       "       'dld_filename', 'dld_getArg', 'urlLen', 'domainlength', 'pathLength',\n",
       "       'subDirLen', 'fileNameLen', 'this.fileExtLen', 'ArgLen', 'pathurlRatio',\n",
       "       'ArgUrlRatio', 'argDomanRatio', 'domainUrlRatio', 'pathDomainRatio',\n",
       "       'argPathRatio', 'executable', 'isPortEighty', 'NumberofDotsinURL',\n",
       "       'ISIpAddressInDomainName', 'CharacterContinuityRate',\n",
       "       'LongestVariableValue', 'URL_DigitCount', 'host_DigitCount',\n",
       "       'Directory_DigitCount', 'File_name_DigitCount', 'Extension_DigitCount',\n",
       "       'Query_DigitCount', 'URL_Letter_Count', 'host_letter_count',\n",
       "       'Directory_LetterCount', 'Filename_LetterCount',\n",
       "       'Extension_LetterCount', 'Query_LetterCount', 'LongestPathTokenLength',\n",
       "       'Domain_LongestWordLength', 'Path_LongestWordLength',\n",
       "       'sub-Directory_LongestWordLength', 'Arguments_LongestWordLength',\n",
       "       'URL_sensitiveWord', 'URLQueries_variable', 'spcharUrl',\n",
       "       'delimeter_Domain', 'delimeter_path', 'delimeter_Count',\n",
       "       'NumberRate_URL', 'NumberRate_Domain', 'NumberRate_DirectoryName',\n",
       "       'NumberRate_FileName', 'NumberRate_Extension', 'NumberRate_AfterPath',\n",
       "       'SymbolCount_URL', 'SymbolCount_Domain', 'SymbolCount_Directoryname',\n",
       "       'SymbolCount_FileName', 'SymbolCount_Extension',\n",
       "       'SymbolCount_Afterpath', 'Entropy_URL', 'Entropy_Domain',\n",
       "       'Entropy_DirectoryName', 'Entropy_Filename', 'Entropy_Extension',\n",
       "       'Entropy_Afterpath', 'URL_Type_obf_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the first rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "vUxge7Pa9kWf",
    "outputId": "ac306fe8-6123-4569-8eed-9ea57e7892a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>SymbolCount_FileName</th>\n",
       "      <th>SymbolCount_Extension</th>\n",
       "      <th>SymbolCount_Afterpath</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_DirectoryName</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>URL_Type_obf_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.726298</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.894886</td>\n",
       "      <td>0.850608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.688635</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.859793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.695049</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.640130</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.663210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>7.333334</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.681307</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "0            0                   4                 5                5.5   \n",
       "1            0                   4                 5                5.5   \n",
       "2            0                   4                 5                5.5   \n",
       "3            0                   4                12                5.5   \n",
       "4            0                   4                 6                5.5   \n",
       "\n",
       "   longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "0                  14         4.400000    4               8            3   \n",
       "1                  14         6.000000    4              12            4   \n",
       "2                  14         5.800000    4              12            5   \n",
       "3                  14         5.500000    4              32           16   \n",
       "4                  14         7.333334    4              18           11   \n",
       "\n",
       "   ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
       "0        0  ...                     1                      0   \n",
       "1        0  ...                     0                      0   \n",
       "2        0  ...                     0                      0   \n",
       "3        0  ...                     0                      0   \n",
       "4        0  ...                     0                      0   \n",
       "\n",
       "   SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  Entropy_DirectoryName  \\\n",
       "0                     -1     0.726298        0.784493               0.894886   \n",
       "1                     -1     0.688635        0.784493               0.814725   \n",
       "2                     -1     0.695049        0.784493               0.814725   \n",
       "3                     -1     0.640130        0.784493               0.814725   \n",
       "4                     -1     0.681307        0.784493               0.814725   \n",
       "\n",
       "   Entropy_Filename  Entropy_Extension  Entropy_Afterpath  URL_Type_obf_Type  \n",
       "0          0.850608                NaN               -1.0         Defacement  \n",
       "1          0.859793                0.0               -1.0         Defacement  \n",
       "2          0.801880                0.0               -1.0         Defacement  \n",
       "3          0.663210                0.0               -1.0         Defacement  \n",
       "4          0.804526                0.0               -1.0         Defacement  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the last rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "LvlO8g5m9pbV",
    "outputId": "358344aa-4bb1-4c2d-fde6-48d3305b637e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>SymbolCount_FileName</th>\n",
       "      <th>SymbolCount_Extension</th>\n",
       "      <th>SymbolCount_Afterpath</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_DirectoryName</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>URL_Type_obf_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36702</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.690555</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.777498</td>\n",
       "      <td>0.690227</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>0.796205</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36703</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>8.461538</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.665492</td>\n",
       "      <td>0.820010</td>\n",
       "      <td>0.879588</td>\n",
       "      <td>0.674400</td>\n",
       "      <td>0.674671</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36704</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>16</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.656807</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.684777</td>\n",
       "      <td>0.713622</td>\n",
       "      <td>0.717187</td>\n",
       "      <td>0.705245</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36705</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>9</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.725963</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.871049</td>\n",
       "      <td>0.745932</td>\n",
       "      <td>0.758824</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36706</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>16</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.674351</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.697282</td>\n",
       "      <td>0.730563</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.769238</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "36702           29                   4                14           5.750000   \n",
       "36703            0                   4                13           3.750000   \n",
       "36704           58                   3                27           6.666666   \n",
       "36705           35                   3                13           4.333334   \n",
       "36706           40                   3                25           6.666666   \n",
       "\n",
       "       longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "36702                  12         3.666667    4              20           24   \n",
       "36703                   8         8.461538    4              24           23   \n",
       "36704                  16         3.375000    3              41           34   \n",
       "36705                   9         3.600000    3              15           13   \n",
       "36706                  16         3.250000    3              35           31   \n",
       "\n",
       "       ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
       "36702        3  ...                     3                      2   \n",
       "36703        0  ...                    16                     15   \n",
       "36704       20  ...                     8                      7   \n",
       "36705        7  ...                     9                      8   \n",
       "36706       19  ...                     7                      6   \n",
       "\n",
       "       SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  \\\n",
       "36702                      7     0.690555        0.791265   \n",
       "36703                     -1     0.665492        0.820010   \n",
       "36704                      9     0.656807        0.801139   \n",
       "36705                      3     0.725963        0.897617   \n",
       "36706                      7     0.674351        0.801139   \n",
       "\n",
       "       Entropy_DirectoryName  Entropy_Filename  Entropy_Extension  \\\n",
       "36702               0.777498          0.690227           0.656684   \n",
       "36703               0.879588          0.674400           0.674671   \n",
       "36704               0.684777          0.713622           0.717187   \n",
       "36705               0.871049          0.745932           0.758824   \n",
       "36706               0.697282          0.730563           0.731481   \n",
       "\n",
       "       Entropy_Afterpath  URL_Type_obf_Type  \n",
       "36702           0.796205               spam  \n",
       "36703          -1.000000               spam  \n",
       "36704           0.705245               spam  \n",
       "36705           0.790772               spam  \n",
       "36706           0.769238               spam  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Vo0Cwne9wRJ"
   },
   "source": [
    "# Functions for Testing\n",
    "> Now that our data has been collected it is time to create functions that will be used in later tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFtoJCs_7T8p"
   },
   "outputs": [],
   "source": [
    "def loadData(csvFile):\n",
    "    pickleDump = '{}.pickle'.format(csvFile)\n",
    "    if os.path.exists(pickleDump):\n",
    "        df = pd.read_pickle(pickleDump)\n",
    "    else:\n",
    "        df = pd.read_csv(csvFile, low_memory=False)\n",
    "        # clean data\n",
    "        # strip the whitspaces from column names\n",
    "        df = df.rename(str.strip, axis='columns')\n",
    "        #df.drop(columns=[], inplace=True)\n",
    "        # drop missing values/NaN etc.\n",
    "        #df.dropna(inplace=True)\n",
    "        # drop Infinity rows and NaN string from each column\n",
    "        for col in df.columns:\n",
    "            indexNames = df[df[col]=='Infinity'].index\n",
    "            if not indexNames.empty:\n",
    "                print('deleting {} rows with Infinity in column {}'.format(len(indexNames), col))\n",
    "                df.drop(indexNames, inplace=True)\n",
    "            indexNames = df[df[col]=='NaN'].index\n",
    "            if not indexNames.empty:\n",
    "                print('deleting {} rows with NaN in column {}'.format(len(indexNames), col))\n",
    "                df.drop(indexNames, inplace=True)\n",
    "        \n",
    "        df.to_pickle(pickleDump)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GB51N0iLCK9J"
   },
   "outputs": [],
   "source": [
    "def baseline_model(feature_layer,inputDim=-1):\n",
    "    global model_name\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_layer,\n",
    "        Dense(128, activation='relu', input_shape=(inputDim,)),\n",
    "    #print(f\"out_shape[1]:{out_shape[1]}\")\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(5, activation='softmax')\n",
    "    ]) #This is the output layer\n",
    "\n",
    "    print('Categorical Cross-Entropy Loss Function')\n",
    "    model_name += \"_categorical\"\n",
    "    model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "#         else:\n",
    "#             model_name += \"_binary\"\n",
    "#             print('Binary Cross-Entropy Loss Function')\n",
    "#             model.compile(optimizer='adam',\n",
    "#                     loss='binary_crossentropy',\n",
    "#                     metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(dataframe):\n",
    "    dataframe=dataframe.copy()\n",
    "    data_y=dataframe.pop(dep_var)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(data_y)\n",
    "    data_y = encoder.transform(data_y)\n",
    "    dummy_y = to_categorical(data_y)\n",
    "    return dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHBhDcKMEPAw"
   },
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    \n",
    "    dataframe=dataframe.copy()\n",
    "    \n",
    "    #Encode the labels as numeric values\n",
    "    labels = encode_labels(dataframe)\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GkZ-uZuz9_pi"
   },
   "source": [
    "# Test LoadData Function\n",
    "> This will look just like the FastAI test, but we are using Tensor, so lets make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_7Y2Ytp7xa-"
   },
   "outputs": [],
   "source": [
    "df1 = loadData('FinalDataset/All.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "4ZwM-GC1-LPj",
    "outputId": "256f437f-fc74-446f-ab21-7bef70cfcb99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Querylength', 'domain_token_count', 'path_token_count',\n",
       "       'avgdomaintokenlen', 'longdomaintokenlen', 'avgpathtokenlen', 'tld',\n",
       "       'charcompvowels', 'charcompace', 'ldl_url', 'ldl_domain', 'ldl_path',\n",
       "       'ldl_filename', 'ldl_getArg', 'dld_url', 'dld_domain', 'dld_path',\n",
       "       'dld_filename', 'dld_getArg', 'urlLen', 'domainlength', 'pathLength',\n",
       "       'subDirLen', 'fileNameLen', 'this.fileExtLen', 'ArgLen', 'pathurlRatio',\n",
       "       'ArgUrlRatio', 'argDomanRatio', 'domainUrlRatio', 'pathDomainRatio',\n",
       "       'argPathRatio', 'executable', 'isPortEighty', 'NumberofDotsinURL',\n",
       "       'ISIpAddressInDomainName', 'CharacterContinuityRate',\n",
       "       'LongestVariableValue', 'URL_DigitCount', 'host_DigitCount',\n",
       "       'Directory_DigitCount', 'File_name_DigitCount', 'Extension_DigitCount',\n",
       "       'Query_DigitCount', 'URL_Letter_Count', 'host_letter_count',\n",
       "       'Directory_LetterCount', 'Filename_LetterCount',\n",
       "       'Extension_LetterCount', 'Query_LetterCount', 'LongestPathTokenLength',\n",
       "       'Domain_LongestWordLength', 'Path_LongestWordLength',\n",
       "       'sub-Directory_LongestWordLength', 'Arguments_LongestWordLength',\n",
       "       'URL_sensitiveWord', 'URLQueries_variable', 'spcharUrl',\n",
       "       'delimeter_Domain', 'delimeter_path', 'delimeter_Count',\n",
       "       'NumberRate_URL', 'NumberRate_Domain', 'NumberRate_DirectoryName',\n",
       "       'NumberRate_FileName', 'NumberRate_Extension', 'NumberRate_AfterPath',\n",
       "       'SymbolCount_URL', 'SymbolCount_Domain', 'SymbolCount_Directoryname',\n",
       "       'SymbolCount_FileName', 'SymbolCount_Extension',\n",
       "       'SymbolCount_Afterpath', 'Entropy_URL', 'Entropy_Domain',\n",
       "       'Entropy_DirectoryName', 'Entropy_Filename', 'Entropy_Extension',\n",
       "       'Entropy_Afterpath', 'URL_Type_obf_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NBvgfW-J--g8",
    "outputId": "29f5e371-9bda-4cfd-9268-3d8e15809c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36697, 80)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "3BZYZgK8-_vO",
    "outputId": "33dd90bb-0320-42a7-ae3a-f3db67e30c83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "5    NaN\n",
       "6    NaN\n",
       "7    NaN\n",
       "8    NaN\n",
       "9    1.0\n",
       "Name: NumberRate_Extension, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['NumberRate_Extension'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6HrsVoNe_EGW",
    "outputId": "d61557c4-e443-47c3-9d88-d79eb3ed8dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36697, 80)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "9eYtvDf5AAR5",
    "outputId": "31b59103-1aa1-454a-acbd-07cbd9648317"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>SymbolCount_FileName</th>\n",
       "      <th>SymbolCount_Extension</th>\n",
       "      <th>SymbolCount_Afterpath</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_DirectoryName</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>URL_Type_obf_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.726298</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.894886</td>\n",
       "      <td>0.850608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.688635</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.859793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.695049</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.640130</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.663210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>7.333334</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.681307</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "0            0                   4                 5                5.5   \n",
       "1            0                   4                 5                5.5   \n",
       "2            0                   4                 5                5.5   \n",
       "3            0                   4                12                5.5   \n",
       "4            0                   4                 6                5.5   \n",
       "\n",
       "   longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "0                  14         4.400000    4               8            3   \n",
       "1                  14         6.000000    4              12            4   \n",
       "2                  14         5.800000    4              12            5   \n",
       "3                  14         5.500000    4              32           16   \n",
       "4                  14         7.333334    4              18           11   \n",
       "\n",
       "   ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
       "0        0  ...                     1                      0   \n",
       "1        0  ...                     0                      0   \n",
       "2        0  ...                     0                      0   \n",
       "3        0  ...                     0                      0   \n",
       "4        0  ...                     0                      0   \n",
       "\n",
       "   SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  Entropy_DirectoryName  \\\n",
       "0                     -1     0.726298        0.784493               0.894886   \n",
       "1                     -1     0.688635        0.784493               0.814725   \n",
       "2                     -1     0.695049        0.784493               0.814725   \n",
       "3                     -1     0.640130        0.784493               0.814725   \n",
       "4                     -1     0.681307        0.784493               0.814725   \n",
       "\n",
       "   Entropy_Filename  Entropy_Extension  Entropy_Afterpath  URL_Type_obf_Type  \n",
       "0          0.850608                NaN               -1.0         Defacement  \n",
       "1          0.859793                0.0               -1.0         Defacement  \n",
       "2          0.801880                0.0               -1.0         Defacement  \n",
       "3          0.663210                0.0               -1.0         Defacement  \n",
       "4          0.804526                0.0               -1.0         Defacement  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f2zcKS_DAGcx"
   },
   "source": [
    "  # Experimenting with Final Dataset/All.csv\n",
    "  \n",
    "  #### Total Samples for each Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "NuFeBCWJABj9",
    "outputId": "3c655ac5-0cfd-4290-9bd9-c17a1b217c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Defacement | 7930 |\n",
      "| spam | 6698 |\n",
      "| malware | 6712 |\n",
      "| benign | 7781 |\n",
      "| phishing | 7586 |\n"
     ]
    }
   ],
   "source": [
    "label = 'URL_Type_obf_Type'\n",
    "lblTypes=set(df[label])\n",
    "for lbl in lblTypes:\n",
    "    print('| {} | {} |'.format(lbl, len(df[df[label] == lbl].index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlTOWuf8A_Yy"
   },
   "outputs": [],
   "source": [
    "dataPath = 'FinalDataset'\n",
    "dep_var = label\n",
    "cont_names = list(set(df.columns) - set(cat_names) - set([dep_var]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "69NkeDAVBSHM",
    "outputId": "b5a7b30d-eb69-4e7d-8c36-f3f8fa41766a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SymbolCount_Directoryname',\n",
       " 'Entropy_URL',\n",
       " 'pathDomainRatio',\n",
       " 'URL_DigitCount',\n",
       " 'argDomanRatio',\n",
       " 'Directory_LetterCount',\n",
       " 'sub-Directory_LongestWordLength',\n",
       " 'isPortEighty',\n",
       " 'domain_token_count',\n",
       " 'domainlength',\n",
       " 'Query_LetterCount',\n",
       " 'charcompvowels',\n",
       " 'CharacterContinuityRate',\n",
       " 'Entropy_Afterpath',\n",
       " 'Domain_LongestWordLength',\n",
       " 'executable',\n",
       " 'ISIpAddressInDomainName',\n",
       " 'tld',\n",
       " 'NumberRate_DirectoryName',\n",
       " 'ArgLen',\n",
       " 'ArgUrlRatio',\n",
       " 'ldl_path',\n",
       " 'host_letter_count',\n",
       " 'argPathRatio',\n",
       " 'dld_path',\n",
       " 'Entropy_Domain',\n",
       " 'Entropy_Extension',\n",
       " 'delimeter_Domain',\n",
       " 'dld_filename',\n",
       " 'ldl_getArg',\n",
       " 'spcharUrl',\n",
       " 'URL_sensitiveWord',\n",
       " 'NumberRate_FileName',\n",
       " 'charcompace',\n",
       " 'fileNameLen',\n",
       " 'NumberRate_Domain',\n",
       " 'avgdomaintokenlen',\n",
       " 'NumberRate_URL',\n",
       " 'URL_Letter_Count',\n",
       " 'delimeter_Count',\n",
       " 'LongestVariableValue',\n",
       " 'pathurlRatio',\n",
       " 'ldl_domain',\n",
       " 'SymbolCount_Domain',\n",
       " 'SymbolCount_Afterpath',\n",
       " 'Arguments_LongestWordLength',\n",
       " 'pathLength',\n",
       " 'subDirLen',\n",
       " 'SymbolCount_Extension',\n",
       " 'NumberofDotsinURL',\n",
       " 'domainUrlRatio',\n",
       " 'SymbolCount_URL',\n",
       " 'Filename_LetterCount',\n",
       " 'URLQueries_variable',\n",
       " 'SymbolCount_FileName',\n",
       " 'Extension_LetterCount',\n",
       " 'ldl_filename',\n",
       " 'dld_url',\n",
       " 'dld_domain',\n",
       " 'delimeter_path',\n",
       " 'File_name_DigitCount',\n",
       " 'path_token_count',\n",
       " 'Path_LongestWordLength',\n",
       " 'Entropy_DirectoryName',\n",
       " 'longdomaintokenlen',\n",
       " 'host_DigitCount',\n",
       " 'Extension_DigitCount',\n",
       " 'avgpathtokenlen',\n",
       " 'Entropy_Filename',\n",
       " 'dld_getArg',\n",
       " 'this.fileExtLen',\n",
       " 'Querylength',\n",
       " 'ldl_url',\n",
       " 'NumberRate_Extension',\n",
       " 'Query_DigitCount',\n",
       " 'LongestPathTokenLength',\n",
       " 'NumberRate_AfterPath',\n",
       " 'urlLen',\n",
       " 'Directory_DigitCount']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast column values to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2nFBzqafCKkG"
   },
   "outputs": [],
   "source": [
    "df1.argPathRatio = df1['argPathRatio'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaUqSRUiItig"
   },
   "source": [
    "# Experimenting with Tensorflow Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4c-GxIVIIZAR"
   },
   "source": [
    "#### Globals for Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-fMOCE2I7MI"
   },
   "outputs": [],
   "source": [
    "dataFile = 'All.csv'\n",
    "optimizer='adam'\n",
    "epochs=10\n",
    "batch_size=10\n",
    "feature_columns = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVt5PyFsFeCm"
   },
   "source": [
    "#### Numeric Columns setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9hq-PiUEXju"
   },
   "outputs": [],
   "source": [
    "#feature columns to classify malicious URLs\n",
    "for header in ['dld_getArg',\n",
    " 'URLQueries_variable',\n",
    " 'Directory_DigitCount',\n",
    " 'URL_sensitiveWord',\n",
    " 'spcharUrl',\n",
    " 'URL_Letter_Count',\n",
    " 'SymbolCount_Directoryname',\n",
    " 'host_DigitCount']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Defacement\n",
       "1        Defacement\n",
       "2        Defacement\n",
       "3        Defacement\n",
       "4        Defacement\n",
       "5        Defacement\n",
       "6        Defacement\n",
       "7        Defacement\n",
       "8        Defacement\n",
       "9        Defacement\n",
       "10       Defacement\n",
       "11       Defacement\n",
       "12       Defacement\n",
       "13       Defacement\n",
       "14       Defacement\n",
       "15       Defacement\n",
       "16       Defacement\n",
       "17       Defacement\n",
       "18       Defacement\n",
       "19       Defacement\n",
       "20       Defacement\n",
       "21       Defacement\n",
       "22       Defacement\n",
       "23       Defacement\n",
       "24       Defacement\n",
       "25       Defacement\n",
       "26       Defacement\n",
       "27       Defacement\n",
       "28       Defacement\n",
       "29       Defacement\n",
       "            ...    \n",
       "36677          spam\n",
       "36678          spam\n",
       "36679          spam\n",
       "36680          spam\n",
       "36681          spam\n",
       "36682          spam\n",
       "36683          spam\n",
       "36684          spam\n",
       "36685          spam\n",
       "36686          spam\n",
       "36687          spam\n",
       "36688          spam\n",
       "36689          spam\n",
       "36690          spam\n",
       "36691          spam\n",
       "36692          spam\n",
       "36693          spam\n",
       "36694          spam\n",
       "36695          spam\n",
       "36696          spam\n",
       "36697          spam\n",
       "36698          spam\n",
       "36699          spam\n",
       "36700          spam\n",
       "36701          spam\n",
       "36702          spam\n",
       "36703          spam\n",
       "36704          spam\n",
       "36705          spam\n",
       "36706          spam\n",
       "Name: URL_Type_obf_Type, Length: 36697, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[dep_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ED-PijliFjJL"
   },
   "source": [
    "#### Training Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8TPcnYhFl_F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputdim =  79\n",
      "[[0 4 5 ... nan -1.0 'Defacement']\n",
      " [0 4 5 ... 0.0 -1.0 'Defacement']\n",
      " [0 4 5 ... 0.0 -1.0 'Defacement']\n",
      " ...\n",
      " [58 3 27 ... 0.717186805 0.7052445629999999 'spam']\n",
      " [35 3 13 ... 0.7588236309999999 0.790771695 'spam']\n",
      " [40 3 25 ... 0.731481013 0.769237864 'spam']]\n",
      "Categorical Cross-Entropy Loss Function\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /usr/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:467 call *\n        raise ValueError('We expected a dictionary here. Instead we got: ',\n\n    ValueError: ('We expected a dictionary here. Instead we got: ', <tf.Tensor 'input_1_4:0' shape=(?, 79) dtype=float32>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9d69d8a83af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputDim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# train, test = train_test_split(df1, test_size=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2556\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2558\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2559\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m       \u001b[0my_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2774\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_training_arg\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /usr/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:467 call *\n        raise ValueError('We expected a dictionary here. Instead we got: ',\n\n    ValueError: ('We expected a dictionary here. Instead we got: ', <tf.Tensor 'input_1_4:0' shape=(?, 79) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "time_gen = int(time.time())\n",
    "global model_name\n",
    "\n",
    "batch_size = 32 # A small batch sized is used for demonstration purposes\n",
    "\n",
    "model_name = f\"{dataFile}_{time_gen}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(model_name))\n",
    "\n",
    "train_ds = df_to_dataset(df1, batch_size=batch_size)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "inputDim = 79\n",
    "print('inputdim = ', inputDim)\n",
    "\n",
    "encode_df = df1.copy()\n",
    "encoded_y = encode_labels(encode_df)\n",
    "\n",
    "\n",
    "y=df1[dep_var].astype('category')\n",
    "X=df1.drop(dep_var,axis=1)\n",
    "\n",
    "for index, (train_indices, val_indices) in enumerate(kfold.split(X, y)):\n",
    "    xtrain, xval = X.iloc[train_indices], X.iloc[val_indices]\n",
    "    ytrain, yval = y.iloc[train_indices], y.iloc[val_indices]\n",
    "    \n",
    "    model = baseline_model(feature_layer, inputDim)\n",
    "    model.fit(x=xtrain.values, y=ytrain, epochs=epochs, validation_data=(xval,yval), callbacks=[tensorboard], batch_size=batch_size)\n",
    "\n",
    "# train, test = train_test_split(df1, test_size=0.2)\n",
    "# train, val = train_test_split(train, test_size=0.2)\n",
    "# val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "# test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "om_Gp7JBF12c"
   },
   "source": [
    "#### Create Data for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UoXrlYBkHmK5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jtMsDc_SGG5F"
   },
   "source": [
    "#### Define dimension of input values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dOU7_-uDGL6V",
    "outputId": "27e89682-9e03-4d57-b489-0ee14038d5ef"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoHKjaqpGQub"
   },
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "vixNeoaEGW9n",
    "outputId": "21555b07-1e20-4267-d2e2-2a98c7b4df3f"
   },
   "outputs": [],
   "source": [
    "model.save('{}.model'.format(os.path.basename(dataPath)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8Rr_75MG617"
   },
   "source": [
    "#### Setup Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "p3xvC6ZlG9Wz",
    "outputId": "775835c4-c56d-4f02-97fe-df8642d9242f"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_ds, verbose=1)\n",
    "print(model.metrics_names)\n",
    "acc, loss=scores[1]*100, scores[0]*100\n",
    "print('Baseline: accuracy: {:.2f}%: loss: {:.2f}'.format(acc, loss))\n",
    "\n",
    "resultFile = os.path.join(resultPath, dataFile)\n",
    "with open('{}.result'.format(resultFile), 'a') as fout:\n",
    "  fout.write('{} results...'.format(model_name))\n",
    "  fout.write('\\taccuracy: {:.2f} loss: {:.2f}\\n'.format(acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Keras-Tensorflow-Experiments.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
